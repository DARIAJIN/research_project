{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "363c06d9-df69-46d7-9c48-eb13a2f681d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.ndimage import map_coordinates\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "os.environ[\"XFORMERS_DISABLED\"] = \"1\"\n",
    "\n",
    "# --------------------------\n",
    "# Path setup (your structure)\n",
    "# --------------------------\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "DATA_ROOT    = PROJECT_ROOT / \"data\"\n",
    "\n",
    "DATA_RAS_DINO = DATA_ROOT / \"ras_1mm_dinoreg\"\n",
    "DATA_COMPLETE = DATA_ROOT / \"complete\"\n",
    "CSV_DIR       = DATA_ROOT / \"csv\"\n",
    "FIG_DIR       = DATA_ROOT / \"fig\" / \"dinoreg\"\n",
    "OUT_TRANSFORM = DATA_ROOT / \"transforms_dinoreg\"\n",
    "OUT_WARP      = DATA_ROOT / \"warp_dinoreg\"\n",
    "\n",
    "# Create dirs\n",
    "for p in [FIG_DIR, OUT_TRANSFORM, OUT_WARP]:\n",
    "    p.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "PAIRS_CSV = CSV_DIR / \"pairs_dinoreg.csv\"\n",
    "\n",
    "STRUCTURES = [\"scapula_left\", \"scapula_right\", \"humerus_left\", \"humerus_right\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50364707-2361-4387-8a5d-133cc6662e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf==2.3.0\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ---------------------------------------- 0.0/79.5 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/79.5 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/79.5 kB ? eta -:--:--\n",
      "     -------------- ----------------------- 30.7/79.5 kB 217.9 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 41.0/79.5 kB 245.8 kB/s eta 0:00:01\n",
      "     ----------------------------- -------- 61.4/79.5 kB 297.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 79.5/79.5 kB 294.7 kB/s eta 0:00:00\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ---------------------------------------- 0.0/117.0 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 10.2/117.0 kB ? eta -:--:--\n",
      "     -------------------- ------------------ 61.4/117.0 kB 1.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- - 112.6/117.0 kB 939.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 117.0/117.0 kB 854.4 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from omegaconf==2.3.0) (6.0.1)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144578 sha256=51f6eed909812c4229268294d04b96ac887d4863d30a569acb7d75dd46322fdd\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\12\\93\\dd\\1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\n",
      "Collecting hydra-core==1.3.2\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "     ---------------------------------------- 0.0/154.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/154.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/154.5 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/154.5 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/154.5 kB 187.9 kB/s eta 0:00:01\n",
      "     --------- --------------------------- 41.0/154.5 kB 196.9 kB/s eta 0:00:01\n",
      "     ----------------- ------------------- 71.7/154.5 kB 262.6 kB/s eta 0:00:01\n",
      "     -------------------------- --------- 112.6/154.5 kB 344.8 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 143.4/154.5 kB 405.9 kB/s eta 0:00:01\n",
      "     ------------------------------------ 154.5/154.5 kB 402.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from hydra-core==1.3.2) (24.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from hydra-core==1.3.2) (4.9.3)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.2 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from hydra-core==1.3.2) (2.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from omegaconf<2.4,>=2.2->hydra-core==1.3.2) (6.0.1)\n",
      "Installing collected packages: hydra-core\n",
      "Successfully installed hydra-core-1.3.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install omegaconf==2.3.0\n",
    "#!pip install hydra-core==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40939127-35ee-4a96-83fc-6fe3c0bf0e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/5.5 MB 165.2 kB/s eta 0:00:34\n",
      "     ---------------------------------------- 0.0/5.5 MB 217.9 kB/s eta 0:00:26\n",
      "     ---------------------------------------- 0.1/5.5 MB 363.1 kB/s eta 0:00:16\n",
      "     - -------------------------------------- 0.2/5.5 MB 1.1 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 0.7/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 1.3/5.5 MB 4.7 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 2.7/5.5 MB 8.3 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 3.6/5.5 MB 9.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.3/5.5 MB 10.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.9/5.5 MB 10.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.5/5.5 MB 11.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.5/5.5 MB 10.1 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-win_amd64.whl (4.7 MB)\n",
      "     ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.5/4.7 MB 15.2 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.0/4.7 MB 12.5 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 1.4/4.7 MB 11.0 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 1.8/4.7 MB 10.4 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 2.3/4.7 MB 10.2 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 2.5/4.7 MB 10.9 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 3.2/4.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 3.5/4.7 MB 10.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 3.7/4.7 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 3.9/4.7 MB 9.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 4.2/4.7 MB 9.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 4.4/4.7 MB 8.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  4.7/4.7 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 4.7/4.7 MB 7.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard) (24.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard) (11.3.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard) (1.26.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "     ---------------------------------------- 0.0/107.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 107.7/107.7 kB 6.1 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "     ---------------------------------------- 0.0/436.9 kB ? eta -:--:--\n",
      "     ------------------------ ------------- 286.7/436.9 kB 8.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 436.9/436.9 kB 6.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard) (67.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from tensorboard) (3.1.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from grpcio>=1.48.2->tensorboard) (4.12.2)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.1)\n",
      "Installing collected packages: tensorboard-data-server, protobuf, markdown, grpcio, tensorboard\n",
      "Successfully installed grpcio-1.76.0 markdown-3.10 protobuf-6.33.2 tensorboard-2.20.0 tensorboard-data-server-0.7.2\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12a23be-be4b-493e-9bf0-68d79fbbd6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torch) (3.9.0)\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp310-cp310-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from sympy>=1.13.3->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\.conda\\envs\\pytorch\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp310-cp310-win_amd64.whl (2817.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp310-cp310-win_amd64.whl (2817.2 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.1\n",
      "    Uninstalling torch-2.9.1:\n",
      "      Successfully uninstalled torch-2.9.1\n",
      "Successfully installed torch-2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "# DONT INSTALL XFORMERS!!!!!\n",
    "#!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "152c5f7d-6b5e-49dc-a549-9773ff86ba50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping xformers as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall xformers -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a1dbc5-667b-4a3b-9a02-29a23979ef2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch OK: 2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch OK:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59369809-dddf-4a09-9a3c-61366001ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xFormers NOT available â€” using torch attention instead\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from dinoReg import dinoReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9b38b2-d03c-4f25-815f-89c8c768d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(a, b):\n",
    "    a = (a > 0).astype(np.uint8)\n",
    "    b = (b > 0).astype(np.uint8)\n",
    "    inter = np.sum(a * b)\n",
    "    return 2 * inter / (np.sum(a) + np.sum(b) + 1e-6)\n",
    "\n",
    "def compute_hd95(a, b):\n",
    "    a_pts = np.transpose(np.nonzero(a))\n",
    "    b_pts = np.transpose(np.nonzero(b))\n",
    "    if len(a_pts)==0 or len(b_pts)==0:\n",
    "        return np.nan\n",
    "    d1 = directed_hausdorff(a_pts, b_pts)[0]\n",
    "    d2 = directed_hausdorff(b_pts, a_pts)[0]\n",
    "    return np.percentile([d1, d2], 95)\n",
    "\n",
    "def save_overlay(fixed, warped_mask, png_path):\n",
    "    mid = fixed.shape[0] // 2\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(fixed[mid], cmap=\"gray\")\n",
    "    plt.imshow(warped_mask[mid], cmap=\"Reds\", alpha=0.4)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(png_path, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a25b13d0-cbd3-4f1d-a835-17360087fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model from your DINO-Reg folder\n",
    "#from dinoReg import dinoReg\n",
    "\n",
    "def run_dinoreg_once(arr_mov, arr_fix, affine, configs):\n",
    "    model = dinoReg(lr=configs['lr'], smooth_weight=configs['smooth_weight'], num_iter=configs['iter_smooth_num'], feat_size=configs['feature_size'])\n",
    "\n",
    "    disp = model.case_inference(\n",
    "        arr_mov,\n",
    "        arr_fix,\n",
    "        arr_mov.shape,\n",
    "        affine,\n",
    "        case_id=\"tmp\",\n",
    "        disp_init=None,\n",
    "        grid_sp_adam=configs[\"fm_downsample\"],\n",
    "        DINOReg_useMask=False\n",
    "    )\n",
    "    return disp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbce3b61-9108-4f4b-8faa-207ff4d6e3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    'smooth_weight' : 2, #50\n",
    "    'lr' : 3,\n",
    "    'num_iter' : 1000,\n",
    "    'fm_downsample' : 1,\n",
    "    'feature_size' : (112,96),\n",
    "        # 'feature_size' : (80,70),\n",
    "        # 'feature_size' : (150,129),\n",
    "    'useSavedPCA' : False,\n",
    "    'DINOReg_useMask' : True,\n",
    "    'window' : True,\n",
    "    'convex' : False,\n",
    "    'ztrans' : False,\n",
    "    'iter_smooth_num': 5,\n",
    "    'iter_smooth_kernel': 7,\n",
    "    'final_upsample': 1,\n",
    "    'mask': 'slice fill stack'\n",
    "    }\n",
    "\n",
    "\n",
    "REPEAT = 3\n",
    "\n",
    "results_csv = CSV_DIR / \"dinoreg_results.csv\"\n",
    "with open(results_csv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"pid\", \"struct\", \"repeat\", \"dice\", \"hd95\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beb3a5ca-de14-427f-a7f4-abf45593a3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['s0970/scapula_left.nii.gz', 's0970/scapula_right.nii.gz'],\n",
       " ['s0970/humerus_left.nii.gz', 's0970/humerus_right.nii.gz'],\n",
       " ['s1029/scapula_left.nii.gz', 's1029/scapula_right.nii.gz'],\n",
       " ['s1029/humerus_left.nii.gz', 's1029/humerus_right.nii.gz'],\n",
       " ['s1124/scapula_left.nii.gz', 's1124/scapula_right.nii.gz']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_list = []\n",
    "with open(PAIRS_CSV, \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        pair_list.append(row)\n",
    "\n",
    "pair_list[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30da72d7-50af-4dbb-9a1c-41f85fa6f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== s0970 / scapula_left ===\n",
      "  Run 1/3\n",
      "DINOv2 model found.\n",
      "learning rate 3\n",
      "preprocessed moving and fixed image, shape (184, 204, 247) (192, 211, 247)\n",
      "14\n",
      "112 96 247\n",
      "resized input shape (1568, 1344, 247)\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 6.90 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 9.44 GiB is allocated by PyTorch, and 40.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mREPEAT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Run DINO-Reg\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m disp \u001b[38;5;241m=\u001b[39m \u001b[43mrun_dinoreg_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr_mov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr_fix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maff_mov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfigs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Save disp\u001b[39;00m\n\u001b[0;32m     41\u001b[0m disp_path \u001b[38;5;241m=\u001b[39m OUT_TRANSFORM \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstruct_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_disp_r\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m, in \u001b[0;36mrun_dinoreg_once\u001b[1;34m(arr_mov, arr_fix, affine, configs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_dinoreg_once\u001b[39m(arr_mov, arr_fix, affine, configs):\n\u001b[0;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m dinoReg(lr\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m], smooth_weight\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmooth_weight\u001b[39m\u001b[38;5;124m'\u001b[39m], num_iter\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter_smooth_num\u001b[39m\u001b[38;5;124m'\u001b[39m], feat_size\u001b[38;5;241m=\u001b[39mconfigs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_size\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m     disp \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcase_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr_mov\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr_fix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr_mov\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcase_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtmp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisp_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_sp_adam\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfigs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfm_downsample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mDINOReg_useMask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disp\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinoReg.py:115\u001b[0m, in \u001b[0;36mdinoReg.case_inference\u001b[1;34m(self, mov_arr, fix_arr, orig_img_shape, aff_mov, mask_fixed, mask_moving, case_id, disp_init, grid_sp_adam, DINOReg_useMask)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed moving and fixed image, shape\u001b[39m\u001b[38;5;124m'\u001b[39m, mov_arr\u001b[38;5;241m.\u001b[39mshape, fix_arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    113\u001b[0m gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m#3\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m mov_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_3D_gap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmov_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded moving image\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    117\u001b[0m fix_feature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_3D_gap(fix_arr, gap\u001b[38;5;241m=\u001b[39mgap)\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinoReg.py:358\u001b[0m, in \u001b[0;36mdinoReg.encode_3D_gap\u001b[1;34m(self, input_arr, gap)\u001b[0m\n\u001b[0;32m    356\u001b[0m input_slice \u001b[38;5;241m=\u001b[39m input_arr[:, :, slice_id, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m    357\u001b[0m input_slice \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(input_slice, \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 358\u001b[0m featrure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_dinov2_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_slice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m featrure \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(featrure, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 n c -> n c\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mslice id:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m feature shape:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(slice_id, featrure\u001b[38;5;241m.\u001b[39mshape), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinoReg.py:95\u001b[0m, in \u001b[0;36mdinoReg.extract_dinov2_feature\u001b[1;34m(self, input_array)\u001b[0m\n\u001b[0;32m     93\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mtranspose(input_rgb_array, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     94\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(input_tensor)\n\u001b[1;32m---> 95\u001b[0m feature_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_norm_patchtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m input_tensor\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m feature_array\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\models\\vision_transformer.py:259\u001b[0m, in \u001b[0;36mDinoVisionTransformer.forward_features\u001b[1;34m(self, x, masks)\u001b[0m\n\u001b[0;32m    256\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_tokens_with_masks(x, masks)\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 259\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m x_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_norm_clstoken\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_norm[:, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_norm_regtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_norm[:, \u001b[38;5;241m1\u001b[39m : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_register_tokens \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m: masks,\n\u001b[0;32m    269\u001b[0m }\n",
      "File \u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\layers\\block.py:254\u001b[0m, in \u001b[0;36mNestedTensorBlock.forward\u001b[1;34m(self, x_or_x_list)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_or_x_list):\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x_or_x_list, Tensor):\n\u001b[1;32m--> 254\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_or_x_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x_or_x_list, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m XFORMERS_AVAILABLE:\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\layers\\block.py:112\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    110\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(ffn_residual_func(x))  \u001b[38;5;66;03m# FIXME: drop_path2\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[43mattn_residual_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m ffn_residual_func(x)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\layers\\block.py:91\u001b[0m, in \u001b[0;36mBlock.forward.<locals>.attn_residual_func\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattn_residual_func\u001b[39m(x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\layers\\attention.py:81\u001b[0m, in \u001b[0;36mMemEffAttention.forward\u001b[1;34m(self, x, attn_bias)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attn_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxFormers is required for using nested tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m B, N, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     84\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqkv(x)\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, C \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n",
      "File \u001b[1;32m~\\Documents\\registration_project\\src\\dinov2\\layers\\attention.py:63\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale, qkv[\u001b[38;5;241m1\u001b[39m], qkv[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     61\u001b[0m attn \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n\u001b[0;32m     66\u001b[0m x \u001b[38;5;241m=\u001b[39m (attn \u001b[38;5;241m@\u001b[39m v)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(B, N, C)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 6.90 GiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 9.44 GiB is allocated by PyTorch, and 40.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "for moving_rel, fixed_rel in pair_list:\n",
    "    subject = moving_rel.split(\"/\")[0]\n",
    "    struct_name = moving_rel.split(\"/\")[1].replace(\".nii.gz\", \"\")\n",
    "\n",
    "    print(f\"=== {subject} / {struct_name} ===\")\n",
    "\n",
    "    moving_path = DATA_RAS_DINO / moving_rel\n",
    "    fixed_path  = DATA_RAS_DINO / fixed_rel\n",
    "\n",
    "    # Load CT ROIs\n",
    "    mov_img = nib.load(str(moving_path))\n",
    "    fix_img = nib.load(str(fixed_path))\n",
    "\n",
    "    arr_mov = mov_img.get_fdata()\n",
    "    arr_fix = fix_img.get_fdata()\n",
    "    aff_mov = mov_img.affine\n",
    "\n",
    "    # Load masks from DATA_COMPLETE\n",
    "    seg_dir = DATA_COMPLETE / subject / \"segmentations\"\n",
    "    mask_mov = nib.load(str(seg_dir / f\"{struct_name}.nii.gz\")).get_fdata()\n",
    "\n",
    "    # Determine opposite side mask\n",
    "    if \"left\" in struct_name:\n",
    "        side2 = struct_name.replace(\"left\", \"right\")\n",
    "    else:\n",
    "        side2 = struct_name.replace(\"right\", \"left\")\n",
    "\n",
    "    mask_fix = nib.load(str(seg_dir / f\"{side2}.nii.gz\")).get_fdata()\n",
    "\n",
    "\n",
    "    # -----------------------\n",
    "    # Repeat N times\n",
    "    # -----------------------\n",
    "    for r in range(REPEAT):\n",
    "        print(f\"  Run {r+1}/{REPEAT}\")\n",
    "\n",
    "        # Run DINO-Reg\n",
    "        disp = run_dinoreg_once(arr_mov, arr_fix, aff_mov, configs)\n",
    "\n",
    "        # Save disp\n",
    "        disp_path = OUT_TRANSFORM / f\"{subject}_{struct_name}_disp_r{r}.nii.gz\"\n",
    "        nib.save(nib.Nifti1Image(disp, aff_mov), str(disp_path))\n",
    "\n",
    "        # Prepare grid for warping\n",
    "        disp_ch = np.moveaxis(disp, 3, 0)\n",
    "        D,H,W = arr_mov.shape\n",
    "        grid = np.meshgrid(np.arange(D), np.arange(H), np.arange(W), indexing='ij')\n",
    "\n",
    "        # Warp moving mask\n",
    "        warped_mask = map_coordinates(mask_mov, grid + disp_ch, order=0)\n",
    "        warp_path = OUT_WARP / f\"{subject}_{struct_name}_maskWarp_r{r}.nii.gz\"\n",
    "        nib.save(nib.Nifti1Image(warped_mask, aff_mov), str(warp_path))\n",
    "\n",
    "        # Save overlay\n",
    "        overlay_png = FIG_DIR / f\"{subject}_{struct_name}_r{r}.png\"\n",
    "        save_overlay(arr_fix, warped_mask, overlay_png)\n",
    "\n",
    "        # Metrics\n",
    "        dice = dice_score(mask_fix, warped_mask)\n",
    "        hd95 = compute_hd95(mask_fix, warped_mask)\n",
    "\n",
    "        print(\"   dice =\", dice, \"  hd95 =\", hd95)\n",
    "\n",
    "        # Append to results csv\n",
    "        with open(results_csv, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([subject, struct_name, r, dice, hd95])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
